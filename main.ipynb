{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f6df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4b66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "playbackScreen = cv.imread('playing.png', cv.IMREAD_UNCHANGED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1d4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandDetector:\n",
    "    INF = 1000\n",
    "\n",
    "    color_scheme = cv.COLOR_BGR2RGB\n",
    "    hands = mp.solutions.hands.Hands()\n",
    "    landmarks = []\n",
    "    closure_threshold = 0.25\n",
    "\n",
    "    @staticmethod\n",
    "    def getLandmarks(frame):\n",
    "        imgColor = cv.cvtColor(frame, HandDetector.color_scheme)\n",
    "        processed = HandDetector.hands.process(imgColor)\n",
    "        result = processed.multi_hand_landmarks\n",
    "        HandDetector.landmarks = result\n",
    "\n",
    "    @staticmethod\n",
    "    def findThumb() -> np.array:\n",
    "        if HandDetector.landmarks != None:\n",
    "            thumbLocation = HandDetector.landmarks[0].landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "            return np.array([thumbLocation.x, thumbLocation.y])\n",
    "        return np.array([])\n",
    "    \n",
    "    @staticmethod\n",
    "    def findIndex() -> np.array:\n",
    "        if HandDetector.landmarks != None:\n",
    "            indexLocation = HandDetector.landmarks[0].landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            \n",
    "            return np.array([indexLocation.x, indexLocation.y])\n",
    "        \n",
    "        return np.array([])\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def getMiddleToWristDistance() -> float:\n",
    "        if HandDetector.landmarks != None:\n",
    "            middleTipLocation = HandDetector.landmarks[0].landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "            wristLocation = HandDetector.landmarks[0].landmark[mp.solutions.hands.HandLandmark.WRIST]\n",
    "\n",
    "            middleTipCoordinate = np.array([middleTipLocation.x, middleTipLocation.y])\n",
    "            wristCoordinate = np.array([wristLocation.x, wristLocation.y])\n",
    "\n",
    "            return np.linalg.norm(middleTipCoordinate - wristCoordinate)\n",
    "        \n",
    "        return HandDetector.INF\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def isClosed() -> bool:\n",
    "        return HandDetector.getMiddleToWristDistance() <= HandDetector.closure_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c5065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 12.32\n",
    "intensity = 100\n",
    "\n",
    "def getShift(dist):\n",
    "    if dist < 0.045:\n",
    "        return intensity\n",
    "    elif 0.045 <= dist <= 0.3:\n",
    "        return intensity * np.cos(sensitivity * (dist - 0.045))\n",
    "    else:\n",
    "        return -1 * intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049f9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_freqShift(freq, frame):\n",
    "    position = (10, 25)\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "\n",
    "    if freq > 0:\n",
    "        color = (0, 100, freq * 255)\n",
    "    else:\n",
    "        color = (-1 * freq * 255, 100, 0)\n",
    "\n",
    "    thickness = 1\n",
    "\n",
    "    cv.putText(frame, str(freq), position, font, font_scale, color, thickness)\n",
    "\n",
    "def draw_playbackScreen(frame):\n",
    "    h, w = playbackScreen.shape[:2]\n",
    "    h = min(h, frame.shape[0])\n",
    "    w = min(w, frame.shape[1])\n",
    "\n",
    "    frame[:h, :w] = playbackScreen[:h, :w]\n",
    "\n",
    "    cv.imshow('cam', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d899f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 44100\n",
    "chunk_duration = 0.25\n",
    "chunk_size = int(samplerate * chunk_duration)\n",
    "\n",
    "def record(cam, handClosed):\n",
    "    audio_chunks = []\n",
    "    pitch_shifts = []\n",
    "\n",
    "    stream = sd.InputStream(samplerate=samplerate, channels=1, blocksize=chunk_size)\n",
    "    stream.start()\n",
    "\n",
    "    while handClosed:\n",
    "        ret, frame = cam.read()\n",
    "        frame = cv.flip(frame, 1)\n",
    "        HandDetector.getLandmarks(frame)\n",
    "        \n",
    "        thumbLoc = HandDetector.findThumb()\n",
    "        indexLoc = HandDetector.findIndex()\n",
    "\n",
    "        audio_chunk, overflowed = stream.read(chunk_size)\n",
    "        audio_chunks.append(audio_chunk[:, 0].copy())\n",
    "\n",
    "        frequency_shift = getShift(np.linalg.norm(thumbLoc - indexLoc))\n",
    "        draw_freqShift(int(100 * (frequency_shift / intensity)) / 100, frame)\n",
    "        pitch_shifts.append(frequency_shift)\n",
    "        \n",
    "    \n",
    "        cv.imshow('cam', frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            exit()\n",
    "\n",
    "        handClosed = HandDetector.isClosed()\n",
    "\n",
    "    stream.stop()\n",
    "\n",
    "    return audio_chunks, pitch_shifts\n",
    "\n",
    "\n",
    "volume = 10.0\n",
    "def playback(cam, audio, pitch_mod):\n",
    "    processed_audio = []\n",
    "\n",
    "    min_len = min(len(audio), len(pitch_mod))\n",
    "    for i in range(min_len):\n",
    "        ret, frame = cam.read()\n",
    "        frame = cv.flip(frame, 1)\n",
    "\n",
    "        draw_playbackScreen(frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            exit()\n",
    "\n",
    "        chunk = audio[i].flatten()\n",
    "        shift = pitch_mod[i]\n",
    "\n",
    "    \n",
    "        if shift > 1:\n",
    "            semitones = np.log2(shift)\n",
    "        elif shift < -1:\n",
    "            semitones = -1 * np.log2(-1 * shift) \n",
    "        else:\n",
    "            semitones = 0\n",
    "\n",
    "        try:\n",
    "            shifted = librosa.effects.pitch_shift(chunk, sr=samplerate, n_steps=semitones, bins_per_octave=12)\n",
    "            processed_audio.append(shifted)\n",
    "        except:\n",
    "            processed_audio.append(chunk)\n",
    "\n",
    "        \n",
    "    \n",
    "    output = np.concatenate(processed_audio)\n",
    "    output *= volume\n",
    "    \n",
    "    sd.play(output, samplerate)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b4e8e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handClosed:\n\u001b[0;32m      9\u001b[0m     recording, shifts \u001b[38;5;241m=\u001b[39m record(cam, handClosed)\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mplayback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshifts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 78\u001b[0m, in \u001b[0;36mplayback\u001b[1;34m(cam, audio, pitch_mod)\u001b[0m\n\u001b[0;32m     75\u001b[0m output \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m volume\n\u001b[0;32m     77\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(output, samplerate)\n\u001b[1;32m---> 78\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wilsp\\miniconda3\\envs\\dfofm\\lib\\site-packages\\sounddevice.py:398\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m \n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wilsp\\miniconda3\\envs\\dfofm\\lib\\site-packages\\sounddevice.py:2645\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m \n\u001b[0;32m   2641\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \n\u001b[0;32m   2643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32mc:\\Users\\wilsp\\miniconda3\\envs\\dfofm\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\wilsp\\miniconda3\\envs\\dfofm\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv.flip(frame, 1)\n",
    "    HandDetector.getLandmarks(frame)\n",
    "\n",
    "    handClosed = HandDetector.isClosed()\n",
    "    if handClosed:\n",
    "        recording, shifts = record(cam, handClosed)\n",
    "        playback(cam, recording, shifts)\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        cam.release()\n",
    "        cv.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "    cv.imshow('cam', frame)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfofm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
